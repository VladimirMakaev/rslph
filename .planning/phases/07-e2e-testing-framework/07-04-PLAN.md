---
phase: 07-e2e-testing-framework
plan: 04
type: execute
wave: 3
depends_on: ["07-03"]
files_modified:
  - tests/e2e/helpers.py
  - tests/e2e/test_basic_loop.py
  - tests/e2e/test_uat_scenarios.py
autonomous: true

must_haves:
  truths:
    - "Verifier helpers can assert task completion in progress files"
    - "Verifier helpers can assert file content and existence"
    - "Verifier helpers can assert git commit history"
    - "UAT demo scenarios show visual testing of full loop"
    - "Basic loop test exercises complete rslph build flow"
  artifacts:
    - path: "tests/e2e/helpers.py"
      provides: "Verifier assertion helpers"
      min_lines: 60
      exports: ["assert_task_complete", "assert_file_contains", "assert_git_has_commit"]
    - path: "tests/e2e/test_basic_loop.py"
      provides: "End-to-end tests of rslph build loop"
      min_lines: 80
    - path: "tests/e2e/test_uat_scenarios.py"
      provides: "UAT demo scenarios for visual testing"
      min_lines: 50
  key_links:
    - from: "tests/e2e/test_basic_loop.py"
      to: "tests/e2e/helpers.py"
      via: "Uses assert_task_complete, assert_file_contains"
      pattern: "assert_(task_complete|file_contains)"
    - from: "tests/e2e/test_uat_scenarios.py"
      to: "fake_claude/scenario.py"
      via: "Creates realistic Claude interaction scenarios"
      pattern: "(respond_with_text|uses_write)"
---

<objective>
Create verifier helpers for test assertions and comprehensive E2E tests including UAT demo scenarios.

Purpose: Complete the E2E testing framework with assertion helpers for common verification patterns and demonstrate full rslph loop testing.

Output: Verifier helpers module and complete E2E test suite exercising the rslph build loop.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-e2e-testing-framework/07-CONTEXT.md

# Prior plan outputs
@.planning/phases/07-e2e-testing-framework/07-01-SUMMARY.md
@.planning/phases/07-e2e-testing-framework/07-02-SUMMARY.md
@.planning/phases/07-e2e-testing-framework/07-03-SUMMARY.md

# Reference for progress file format
@src/progress.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create verifier helpers module</name>
  <files>
    tests/e2e/helpers.py
  </files>
  <action>
Create `tests/e2e/helpers.py` with assertion helpers per phase requirements:

```python
"""Verifier helpers for E2E test assertions."""
import subprocess
import re
from pathlib import Path
from typing import Optional

def assert_task_complete(workspace, task_pattern: str, msg: str = None):
    """Assert a task is marked complete in PROGRESS.md.

    Args:
        workspace: Workspace fixture
        task_pattern: Regex pattern to match task description
        msg: Optional assertion message
    """
    progress_path = workspace.path / "PROGRESS.md"
    assert progress_path.exists(), f"PROGRESS.md not found at {progress_path}"

    content = progress_path.read_text()
    # Match: - [x] Task description
    pattern = rf"^- \[x\].*{task_pattern}"
    match = re.search(pattern, content, re.MULTILINE | re.IGNORECASE)

    assert match is not None, msg or f"Task matching '{task_pattern}' not marked complete"

def assert_task_incomplete(workspace, task_pattern: str, msg: str = None):
    """Assert a task is NOT marked complete in PROGRESS.md."""
    progress_path = workspace.path / "PROGRESS.md"
    assert progress_path.exists(), f"PROGRESS.md not found"

    content = progress_path.read_text()
    pattern = rf"^- \[ \].*{task_pattern}"
    match = re.search(pattern, content, re.MULTILINE | re.IGNORECASE)

    assert match is not None, msg or f"Task matching '{task_pattern}' not found as incomplete"

def assert_ralph_done(workspace, msg: str = None):
    """Assert PROGRESS.md contains RALPH_DONE marker."""
    progress_path = workspace.path / "PROGRESS.md"
    assert progress_path.exists(), f"PROGRESS.md not found"

    content = progress_path.read_text()
    assert "RALPH_DONE" in content, msg or "RALPH_DONE marker not found"

def assert_file_contains(workspace, rel_path: str, pattern: str, msg: str = None):
    """Assert file contains text matching pattern.

    Args:
        workspace: Workspace fixture
        rel_path: Path relative to workspace
        pattern: Regex pattern to search for
        msg: Optional assertion message
    """
    file_path = workspace.path / rel_path
    assert file_path.exists(), f"File not found: {file_path}"

    content = file_path.read_text()
    match = re.search(pattern, content, re.MULTILINE)

    assert match is not None, msg or f"Pattern '{pattern}' not found in {rel_path}"

def assert_file_not_contains(workspace, rel_path: str, pattern: str, msg: str = None):
    """Assert file does NOT contain text matching pattern."""
    file_path = workspace.path / rel_path
    if not file_path.exists():
        return  # File not existing means it doesn't contain the pattern

    content = file_path.read_text()
    match = re.search(pattern, content, re.MULTILINE)

    assert match is None, msg or f"Pattern '{pattern}' should not be in {rel_path}"

def assert_file_exists(workspace, rel_path: str, msg: str = None):
    """Assert file exists in workspace."""
    file_path = workspace.path / rel_path
    assert file_path.exists(), msg or f"File not found: {rel_path}"

def assert_file_not_exists(workspace, rel_path: str, msg: str = None):
    """Assert file does NOT exist in workspace."""
    file_path = workspace.path / rel_path
    assert not file_path.exists(), msg or f"File should not exist: {rel_path}"

def assert_git_has_commit(workspace, message_pattern: str, msg: str = None):
    """Assert git log contains a commit matching message pattern.

    Args:
        workspace: Workspace fixture
        message_pattern: Regex pattern to match commit message
        msg: Optional assertion message
    """
    result = subprocess.run(
        ["git", "log", "--oneline", "-20"],
        cwd=workspace.path,
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f"git log failed: {result.stderr}"

    match = re.search(message_pattern, result.stdout, re.IGNORECASE)
    assert match is not None, msg or f"No commit matching '{message_pattern}' in git log"

def assert_git_clean(workspace, msg: str = None):
    """Assert working directory has no uncommitted changes."""
    result = subprocess.run(
        ["git", "status", "--porcelain"],
        cwd=workspace.path,
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f"git status failed: {result.stderr}"
    assert result.stdout.strip() == "", msg or f"Working directory not clean: {result.stdout}"

def assert_git_has_staged(workspace, file_pattern: str, msg: str = None):
    """Assert there are staged changes matching pattern."""
    result = subprocess.run(
        ["git", "diff", "--cached", "--name-only"],
        cwd=workspace.path,
        capture_output=True,
        text=True
    )
    assert result.returncode == 0, f"git diff failed: {result.stderr}"

    match = re.search(file_pattern, result.stdout)
    assert match is not None, msg or f"No staged file matching '{file_pattern}'"

def get_progress_tasks(workspace) -> list[tuple[bool, str]]:
    """Parse PROGRESS.md and return list of (completed, description) tuples."""
    progress_path = workspace.path / "PROGRESS.md"
    if not progress_path.exists():
        return []

    content = progress_path.read_text()
    tasks = []

    for line in content.split('\n'):
        # Match: - [x] Task or - [ ] Task
        match = re.match(r'^- \[([ x])\]\s*(.+)$', line)
        if match:
            completed = match.group(1) == 'x'
            description = match.group(2).strip()
            tasks.append((completed, description))

    return tasks
```
  </action>
  <verify>
```bash
cd /Users/vmakaev/NonWork/rslph
python3 -c "
from tests.e2e.helpers import assert_task_complete, assert_file_contains, assert_git_has_commit
print('Helper imports OK')
"
```
  </verify>
  <done>Verifier helpers module created with all assertion functions</done>
</task>

<task type="auto">
  <name>Task 2: Create basic loop E2E tests</name>
  <files>
    tests/e2e/test_basic_loop.py
  </files>
  <action>
Create `tests/e2e/test_basic_loop.py` with E2E tests of complete rslph build flow:

```python
"""End-to-end tests of the rslph build loop."""
import subprocess
from fake_claude import fake_claude
from tests.e2e.helpers import (
    assert_task_complete,
    assert_ralph_done,
    assert_file_contains,
    assert_file_exists,
)

# Sample progress files
PROGRESS_ONE_TASK = """# Tasks
- [ ] Task 1: Create hello.txt with "Hello World"
"""

PROGRESS_ONE_TASK_DONE = """# Tasks
- [x] Task 1: Create hello.txt with "Hello World"
RALPH_DONE
"""

PROGRESS_MULTI_TASK = """# Tasks
- [ ] Task 1: Create config.json
- [ ] Task 2: Create main.py
- [ ] Task 3: Write tests
"""

def test_single_task_completion(workspace, rslph_binary):
    """Claude completes a single task and marks RALPH_DONE."""
    scenario = (
        fake_claude()
        .on_invocation(1)
        .respond_with_text("I'll create hello.txt for you.")
        .uses_write("hello.txt", "Hello World")
        .uses_write("PROGRESS.md", PROGRESS_ONE_TASK_DONE)
        .build()
    )

    workspace.with_claude_path(scenario.executable_path)
    workspace.write_progress(PROGRESS_ONE_TASK)
    workspace.commit_all("Initial commit")

    result = subprocess.run(
        [str(rslph_binary), "build", "--max-iterations", "1"],
        cwd=workspace.path,
        capture_output=True,
        text=True,
        timeout=60
    )

    # Verify file was "created" (via tool use output)
    assert scenario.get_invocation_count() == 1
    scenario.cleanup()

def test_max_iterations_limit(workspace, rslph_binary):
    """Build stops after max iterations even if not done."""
    scenario = (
        fake_claude()
        .on_invocation(1)
        .respond_with_text("Working on task 1...")
        .next_invocation()
        .respond_with_text("Still working...")
        .next_invocation()
        .respond_with_text("More work...")
        .build()
    )

    workspace.with_claude_path(scenario.executable_path)
    workspace.write_progress(PROGRESS_MULTI_TASK)
    workspace.commit_all("Initial")

    result = subprocess.run(
        [str(rslph_binary), "build", "--max-iterations", "2"],
        cwd=workspace.path,
        capture_output=True,
        text=True,
        timeout=60
    )

    # Should have called exactly 2 times (max-iterations limit)
    assert scenario.get_invocation_count() == 2
    scenario.cleanup()

def test_ralph_done_stops_loop(workspace, rslph_binary):
    """Build stops when RALPH_DONE is detected."""
    progress_done = """# Tasks
- [x] All tasks complete
RALPH_DONE
"""

    scenario = (
        fake_claude()
        .on_invocation(1)
        .respond_with_text("All done!")
        .uses_write("PROGRESS.md", progress_done)
        .next_invocation()
        .respond_with_text("This should not be called")
        .build()
    )

    workspace.with_claude_path(scenario.executable_path)
    workspace.write_progress("# Tasks\n- [ ] Task 1")
    workspace.commit_all("Initial")

    result = subprocess.run(
        [str(rslph_binary), "build", "--max-iterations", "10"],
        cwd=workspace.path,
        capture_output=True,
        text=True,
        timeout=60
    )

    # Should stop after first iteration (RALPH_DONE written)
    assert scenario.get_invocation_count() == 1
    scenario.cleanup()

def test_tool_use_read(workspace, rslph_binary):
    """Claude can use Read tool in scenario."""
    scenario = (
        fake_claude()
        .on_invocation(1)
        .respond_with_text("Let me read the config")
        .uses_read("config.toml")
        .respond_with_text("Config looks good")
        .build()
    )

    workspace.with_claude_path(scenario.executable_path)
    workspace.write_file("config.toml", "[settings]\nkey = 'value'")
    workspace.write_progress("# Tasks\n- [ ] Check config")
    workspace.commit_all("Initial")

    result = subprocess.run(
        [str(rslph_binary), "build", "--max-iterations", "1"],
        cwd=workspace.path,
        capture_output=True,
        text=True,
        timeout=60
    )

    assert scenario.get_invocation_count() == 1
    scenario.cleanup()

def test_tool_use_bash(workspace, rslph_binary):
    """Claude can use Bash tool in scenario."""
    scenario = (
        fake_claude()
        .on_invocation(1)
        .respond_with_text("Running tests")
        .uses_bash("echo 'test passed'")
        .respond_with_text("Tests passed!")
        .build()
    )

    workspace.with_claude_path(scenario.executable_path)
    workspace.write_progress("# Tasks\n- [ ] Run tests")
    workspace.commit_all("Initial")

    result = subprocess.run(
        [str(rslph_binary), "build", "--max-iterations", "1"],
        cwd=workspace.path,
        capture_output=True,
        text=True,
        timeout=60
    )

    assert scenario.get_invocation_count() == 1
    scenario.cleanup()

def test_claude_failure_continues(workspace, rslph_binary):
    """Build continues to next iteration after Claude failure."""
    progress_done = """# Tasks
- [x] Task 1
RALPH_DONE
"""

    scenario = (
        fake_claude()
        .on_invocation(1)
        .respond_with_text("Oops, error")
        .with_exit_code(1)  # First call fails
        .next_invocation()
        .respond_with_text("Fixed!")
        .uses_write("PROGRESS.md", progress_done)
        .build()
    )

    workspace.with_claude_path(scenario.executable_path)
    workspace.write_progress("# Tasks\n- [ ] Task 1")
    workspace.commit_all("Initial")

    result = subprocess.run(
        [str(rslph_binary), "build", "--max-iterations", "3"],
        cwd=workspace.path,
        capture_output=True,
        text=True,
        timeout=60
    )

    # Should have called twice (first failed, second succeeded)
    assert scenario.get_invocation_count() >= 2
    scenario.cleanup()
```
  </action>
  <verify>
```bash
cd /Users/vmakaev/NonWork/rslph
python3 -m pytest tests/e2e/test_basic_loop.py -v --tb=short -x
```
  </verify>
  <done>Basic loop tests exercise complete rslph build flow with fake Claude</done>
</task>

<task type="auto">
  <name>Task 3: Create UAT demo scenarios</name>
  <files>
    tests/e2e/test_uat_scenarios.py
  </files>
  <action>
Create `tests/e2e/test_uat_scenarios.py` with realistic UAT demo scenarios:

```python
"""UAT demo scenarios for visual testing of rslph.

These tests demonstrate realistic usage patterns and can be run
manually for visual verification of TUI behavior.

Run with: pytest tests/e2e/test_uat_scenarios.py -v -s
(The -s flag shows stdout for visual inspection)
"""
import subprocess
import time
from fake_claude import fake_claude
from tests.e2e.helpers import assert_ralph_done

# Realistic progress file for a small feature
FEATURE_PROGRESS = """# Feature: Add User Authentication

## Tasks
- [ ] Create User model with email and password hash
- [ ] Implement bcrypt password hashing utility
- [ ] Create /api/auth/register endpoint
- [ ] Create /api/auth/login endpoint
- [ ] Add JWT token generation

## Notes
- Use bcrypt with 12 rounds
- JWT expiry: 15 minutes
"""

FEATURE_PROGRESS_DONE = """# Feature: Add User Authentication

## Tasks
- [x] Create User model with email and password hash
- [x] Implement bcrypt password hashing utility
- [x] Create /api/auth/register endpoint
- [x] Create /api/auth/login endpoint
- [x] Add JWT token generation

## Notes
- Use bcrypt with 12 rounds
- JWT expiry: 15 minutes

RALPH_DONE
"""


class TestUATScenarios:
    """UAT scenarios demonstrating realistic rslph usage."""

    def test_uat_happy_path_feature_completion(self, workspace, rslph_binary):
        """
        UAT: Developer completes a feature in one iteration.

        Visual verification:
        - TUI shows iteration starting
        - Progress bar advances
        - Task completion displayed
        - RALPH_DONE detected
        """
        scenario = (
            fake_claude()
            .on_invocation(1)
            .with_thinking("Let me analyze the tasks and implement the auth feature.")
            .respond_with_text("I'll implement the user authentication feature.")
            .uses_read("package.json")  # Check dependencies
            .respond_with_text("Adding the User model...")
            .uses_write("src/models/User.ts", "export interface User { id: string; email: string; passwordHash: string; }")
            .respond_with_text("Adding password hashing...")
            .uses_write("src/utils/password.ts", "import bcrypt from 'bcrypt';\nexport const hash = (pw: string) => bcrypt.hashSync(pw, 12);")
            .respond_with_text("Creating auth endpoints...")
            .uses_write("src/api/auth/register.ts", "// Register endpoint")
            .uses_write("src/api/auth/login.ts", "// Login endpoint")
            .respond_with_text("Adding JWT generation...")
            .uses_write("src/utils/jwt.ts", "// JWT utilities")
            .respond_with_text("All tasks complete! Updating progress.")
            .uses_write("PROGRESS.md", FEATURE_PROGRESS_DONE)
            .build()
        )

        workspace.with_claude_path(scenario.executable_path)
        workspace.write_progress(FEATURE_PROGRESS)
        workspace.commit_all("Initial feature setup")

        print("\n=== UAT: Happy Path Feature Completion ===")
        print(f"Workspace: {workspace.path}")
        print("Running rslph build...")

        result = subprocess.run(
            [str(rslph_binary), "build", "--max-iterations", "3"],
            cwd=workspace.path,
            capture_output=True,
            text=True,
            timeout=120
        )

        print(f"Exit code: {result.returncode}")
        print(f"Invocations: {scenario.get_invocation_count()}")

        # Verify completion
        assert scenario.get_invocation_count() == 1, "Should complete in one iteration"
        scenario.cleanup()

    def test_uat_multi_iteration_with_issues(self, workspace, rslph_binary):
        """
        UAT: Developer needs multiple iterations due to issues.

        Visual verification:
        - First iteration encounters problem
        - Second iteration fixes it
        - Progress shows recovery
        """
        partial_done = """# Tasks
- [x] Task 1: Setup
- [ ] Task 2: Implementation (had build error, retrying)
"""
        full_done = """# Tasks
- [x] Task 1: Setup
- [x] Task 2: Implementation
RALPH_DONE
"""

        scenario = (
            fake_claude()
            .on_invocation(1)
            .respond_with_text("Setting up the project...")
            .uses_write("src/index.ts", "// Initial setup with typo: cont x = 1;")
            .uses_write("PROGRESS.md", partial_done)
            .respond_with_text("Hmm, there was a build error. I'll fix it next iteration.")
            .next_invocation()
            .respond_with_text("Fixing the typo from last iteration...")
            .uses_write("src/index.ts", "// Fixed: const x = 1;")
            .uses_write("PROGRESS.md", full_done)
            .build()
        )

        workspace.with_claude_path(scenario.executable_path)
        workspace.write_progress("# Tasks\n- [ ] Task 1: Setup\n- [ ] Task 2: Implementation")
        workspace.commit_all("Initial")

        print("\n=== UAT: Multi-Iteration with Issues ===")
        print(f"Workspace: {workspace.path}")

        result = subprocess.run(
            [str(rslph_binary), "build", "--max-iterations", "5"],
            cwd=workspace.path,
            capture_output=True,
            text=True,
            timeout=120
        )

        print(f"Invocations: {scenario.get_invocation_count()}")

        assert scenario.get_invocation_count() == 2, "Should complete in two iterations"
        scenario.cleanup()

    def test_uat_thinking_blocks_display(self, workspace, rslph_binary):
        """
        UAT: Verify thinking blocks are displayed appropriately.

        Visual verification:
        - Thinking text shown (if enabled)
        - Response text follows thinking
        """
        scenario = (
            fake_claude()
            .on_invocation(1)
            .with_thinking("Let me analyze this carefully. The user wants a simple greeting function. I should create a clean, well-documented function.")
            .respond_with_text("I'll create a greeting function for you.")
            .uses_write("greet.py", "def greet(name: str) -> str:\n    return f'Hello, {name}!'")
            .uses_write("PROGRESS.md", "# Tasks\n- [x] Create greeting function\nRALPH_DONE")
            .build()
        )

        workspace.with_claude_path(scenario.executable_path)
        workspace.write_progress("# Tasks\n- [ ] Create greeting function")
        workspace.commit_all("Initial")

        print("\n=== UAT: Thinking Blocks Display ===")

        result = subprocess.run(
            [str(rslph_binary), "build", "--max-iterations", "1"],
            cwd=workspace.path,
            capture_output=True,
            text=True,
            timeout=60
        )

        assert scenario.get_invocation_count() == 1
        scenario.cleanup()

    def test_uat_slow_response_handling(self, workspace, rslph_binary):
        """
        UAT: Verify TUI handles slow/streaming responses well.

        Visual verification:
        - Progress indicator shows activity
        - No timeout during slow output
        - Response accumulates visibly
        """
        scenario = (
            fake_claude()
            .on_invocation(1)
            .respond_with_text("Starting slow operation...")
            .with_delay(0.3)  # 300ms between outputs
            .respond_with_text("Still working...")
            .respond_with_text("Almost there...")
            .respond_with_text("Done!")
            .uses_write("PROGRESS.md", "# Tasks\n- [x] Slow task\nRALPH_DONE")
            .build()
        )

        workspace.with_claude_path(scenario.executable_path)
        workspace.write_progress("# Tasks\n- [ ] Slow task")
        workspace.commit_all("Initial")

        print("\n=== UAT: Slow Response Handling ===")

        start = time.time()
        result = subprocess.run(
            [str(rslph_binary), "build", "--max-iterations", "1"],
            cwd=workspace.path,
            capture_output=True,
            text=True,
            timeout=120
        )
        elapsed = time.time() - start

        print(f"Elapsed: {elapsed:.1f}s (expected ~1s for delays)")

        assert scenario.get_invocation_count() == 1
        scenario.cleanup()
```
  </action>
  <verify>
```bash
cd /Users/vmakaev/NonWork/rslph
python3 -m pytest tests/e2e/test_uat_scenarios.py -v --tb=short
```
  </verify>
  <done>UAT demo scenarios created for visual testing of complete rslph loop</done>
</task>

</tasks>

<verification>
```bash
cd /Users/vmakaev/NonWork/rslph

# Run all E2E tests
python3 -m pytest tests/e2e/ -v --tb=short

# Count test files and tests
echo "Test files:"
ls tests/e2e/test_*.py

echo "Total tests:"
python3 -m pytest tests/e2e/ --collect-only -q | tail -1
```
</verification>

<success_criteria>
1. `tests/e2e/helpers.py` exists with all assertion functions
2. Helpers work: assert_task_complete, assert_file_contains, assert_git_has_commit
3. `test_basic_loop.py` exercises complete rslph build flow
4. `test_uat_scenarios.py` provides realistic demo scenarios
5. All E2E tests pass: `python3 -m pytest tests/e2e/ -v`
6. Test count: At least 20 total E2E tests across all files
</success_criteria>

<output>
After completion, create `.planning/phases/07-e2e-testing-framework/07-04-SUMMARY.md`
</output>
