---
phase: 07-e2e-testing-framework
plan: 04
type: execute
wave: 3
depends_on: ["07-01", "07-02", "07-03"]
files_modified:
  - tests/e2e/test_basic_loop.rs
  - tests/e2e/test_edge_cases.rs
  - tests/e2e/mod.rs
  - Cargo.toml
autonomous: true

must_haves:
  truths:
    - "Basic build loop completes successfully with fake Claude"
    - "Edge cases are tested (crash, timeout, malformed output)"
    - "Multi-invocation scenarios work end-to-end"
    - "All infrastructure integrates correctly"
  artifacts:
    - path: "tests/e2e/test_basic_loop.rs"
      provides: "E2E tests for basic loop scenarios"
      min_lines: 50
    - path: "tests/e2e/test_edge_cases.rs"
      provides: "E2E tests for edge cases"
      min_lines: 40
  key_links:
    - from: "tests/e2e/test_basic_loop.rs"
      to: "tests/fake_claude/scenario.rs"
      via: "tests use ScenarioBuilder"
      pattern: "ScenarioBuilder::new"
    - from: "tests/e2e/test_basic_loop.rs"
      to: "tests/e2e/fixtures.rs"
      via: "tests use WorkspaceBuilder"
      pattern: "WorkspaceBuilder::new"
---

<objective>
Create E2E integration tests using all the testing infrastructure.

Purpose: Verify complete integration of fake Claude, workspace fixtures, and verifier helpers. Prove the testing framework works for real scenarios.

Output: Working E2E tests that exercise the full rslph build loop with fake Claude.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-e2e-testing-framework/07-RESEARCH.md

# Prior plan artifacts (will exist after prior plans complete)
# @.planning/phases/07-e2e-testing-framework/07-01-SUMMARY.md
# @.planning/phases/07-e2e-testing-framework/07-02-SUMMARY.md
# @.planning/phases/07-e2e-testing-framework/07-03-SUMMARY.md

# Key source files
@src/build/command.rs
@src/progress.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update e2e module and add test dependencies</name>
  <files>tests/e2e/mod.rs, Cargo.toml</files>
  <action>
Update tests/e2e/mod.rs to include test modules:

```rust
pub mod fixtures;
pub mod helpers;

// Test modules
mod test_basic_loop;
mod test_edge_cases;

pub use fixtures::{Workspace, WorkspaceBuilder};
pub use helpers::*;
```

Check Cargo.toml has assert_cmd for command testing. If not already present from Plan 01, ensure:
```toml
[dev-dependencies]
assert_cmd = "2"
```

Note: TUI testing with ratatui-testlib is deferred to a future plan. The v0.1.0 crate needs API verification and may require custom solutions. For now, focus on CLI-level E2E tests.
  </action>
  <verify>
- `cargo check --tests` succeeds
- Module structure compiles
  </verify>
  <done>E2E test module structure is set up</done>
</task>

<task type="auto">
  <name>Task 2: Create basic loop E2E tests</name>
  <files>tests/e2e/test_basic_loop.rs</files>
  <action>
Create test_basic_loop.rs with integration tests that use the full infrastructure.

Important: These tests need to invoke the rslph binary with the fake Claude. Use assert_cmd for this.

```rust
//! Basic build loop E2E tests

use crate::e2e::{WorkspaceBuilder, assert_file_contains};
use crate::fake_claude::ScenarioBuilder;
use assert_cmd::Command;
use std::time::Duration;

/// Get path to rslph binary
fn rslph_bin() -> Command {
    Command::cargo_bin("rslph").expect("rslph binary should exist")
}

#[test]
fn test_fake_claude_outputs_text() {
    // Verify fake Claude itself works
    let scenario = ScenarioBuilder::new()
        .respond_with_text("Hello from fake Claude!")
        .build();

    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");

    let stdout = String::from_utf8_lossy(&output.stdout);
    assert!(stdout.contains("Hello from fake Claude!"));
    assert!(output.status.success());
}

#[test]
fn test_fake_claude_tool_call_format() {
    // Verify tool calls output correct JSON
    let scenario = ScenarioBuilder::new()
        .uses_read("/test/file.txt")
        .build();

    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");

    let stdout = String::from_utf8_lossy(&output.stdout);
    assert!(stdout.contains("tool_use"));
    assert!(stdout.contains("Read"));
    assert!(stdout.contains("/test/file.txt"));
}

#[test]
fn test_fake_claude_multi_invocation() {
    // Verify multi-invocation counter works
    let scenario = ScenarioBuilder::new()
        .respond_with_text("First invocation")
        .next_invocation()
        .respond_with_text("Second invocation")
        .build();

    // First invocation
    let output1 = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");
    let stdout1 = String::from_utf8_lossy(&output1.stdout);
    assert!(stdout1.contains("First invocation"));

    // Second invocation
    let output2 = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");
    let stdout2 = String::from_utf8_lossy(&output2.stdout);
    assert!(stdout2.contains("Second invocation"));

    assert_eq!(scenario.invocation_count(), 2);
}

#[test]
fn test_workspace_fixture_creates_valid_structure() {
    let workspace = WorkspaceBuilder::new()
        .with_progress_file("- [ ] Task 1\n- [ ] Task 2")
        .with_source_file("src/main.rs", "fn main() {}")
        .build();

    // Verify structure
    assert!(workspace.file_exists("PROGRESS.md"));
    assert!(workspace.file_exists("src/main.rs"));
    assert!(workspace.file_exists(".rslph/config.toml"));
    assert!(workspace.path().join(".git").exists());

    // Verify content
    assert_file_contains(&workspace, "PROGRESS.md", "Task 1");
    assert_file_contains(&workspace, "src/main.rs", "fn main()");
}

// Note: Full rslph integration tests require more setup.
// The following is a placeholder for when rslph is configured to accept
// a custom Claude path via CLI or config.

#[test]
#[ignore = "Requires rslph --claude-path support or RSLPH_CLAUDE_PATH env"]
fn test_rslph_with_fake_claude_basic() {
    let scenario = ScenarioBuilder::new()
        .respond_with_text("Working on the task...")
        .uses_bash("echo done")
        .build();

    let workspace = WorkspaceBuilder::new()
        .with_progress_file("- [ ] Task 1")
        .build();

    // This test would run:
    // rslph build --claude-path /path/to/fake_claude
    // with FAKE_CLAUDE_CONFIG set

    // For now, verify the setup works
    assert!(scenario.executable_path.exists() || scenario.config_path.exists());
}
```
  </action>
  <verify>
- `cargo test e2e::test_basic_loop --` passes
- Fake Claude output tests pass
- Multi-invocation test passes
  </verify>
  <done>Basic loop E2E tests verify infrastructure works</done>
</task>

<task type="auto">
  <name>Task 3: Create edge case E2E tests</name>
  <files>tests/e2e/test_edge_cases.rs</files>
  <action>
Create test_edge_cases.rs with edge case scenario tests:

```rust
//! Edge case E2E tests

use crate::fake_claude::ScenarioBuilder;
use std::time::{Duration, Instant};

#[test]
fn test_fake_claude_crash_after_events() {
    let scenario = ScenarioBuilder::new()
        .respond_with_text("Event 1")
        .respond_with_text("Event 2")
        .crash_after(1) // Crash after first event
        .build();

    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");

    // Should have crashed with non-zero exit
    assert!(!output.status.success());

    // Should have output only first event
    let stdout = String::from_utf8_lossy(&output.stdout);
    assert!(stdout.contains("Event 1"));
    // Event 2 should NOT be in output (crashed before)
}

#[test]
fn test_fake_claude_with_delay() {
    let delay_ms = 50;

    let scenario = ScenarioBuilder::new()
        .respond_with_text("Event 1")
        .respond_with_text("Event 2")
        .respond_with_text("Event 3")
        .with_delay(delay_ms)
        .build();

    let start = Instant::now();
    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");
    let elapsed = start.elapsed();

    assert!(output.status.success());

    // Should have taken at least 3 * delay_ms (3 events with delay each)
    // Use 2.5x to account for timing variance
    assert!(
        elapsed >= Duration::from_millis(delay_ms * 2),
        "Expected delay, but took only {:?}",
        elapsed
    );
}

#[test]
fn test_fake_claude_malformed_output() {
    let scenario = ScenarioBuilder::new()
        .send_raw("this is not json at all")
        .send_raw("{incomplete json")
        .respond_with_text("Normal event after malformed")
        .build();

    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");

    let stdout = String::from_utf8_lossy(&output.stdout);

    // All raw lines should appear
    assert!(stdout.contains("this is not json at all"));
    assert!(stdout.contains("{incomplete json"));
    // Normal event should also appear
    assert!(stdout.contains("Normal event"));
}

#[test]
fn test_fake_claude_custom_exit_code() {
    let scenario = ScenarioBuilder::new()
        .respond_with_text("Will exit with code 42")
        .with_exit_code(42)
        .build();

    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");

    assert!(!output.status.success());

    #[cfg(unix)]
    {
        use std::os::unix::process::ExitStatusExt;
        assert_eq!(output.status.code(), Some(42));
    }
}

#[test]
fn test_fake_claude_unconfigured_invocation() {
    // Configure only 1 invocation
    let scenario = ScenarioBuilder::new()
        .respond_with_text("Only first configured")
        .build();

    // First invocation - should output response
    let output1 = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");
    assert!(String::from_utf8_lossy(&output1.stdout).contains("Only first configured"));

    // Second invocation - unconfigured, should exit silently with 0
    let output2 = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");
    assert!(output2.status.success());
    assert!(output2.stdout.is_empty() || String::from_utf8_lossy(&output2.stdout).trim().is_empty());
}

#[test]
fn test_fake_claude_empty_scenario() {
    // No events configured
    let scenario = ScenarioBuilder::new().build();

    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");

    // Should succeed with no output
    assert!(output.status.success());
}

#[test]
fn test_fake_claude_rapid_output() {
    // Many events with no delay - tests "fast output" scenario
    let mut builder = ScenarioBuilder::new();
    for i in 0..100 {
        builder = builder.respond_with_text(&format!("Event {}", i));
    }
    let scenario = builder.build();

    let output = std::process::Command::new(&scenario.executable_path)
        .env("FAKE_CLAUDE_CONFIG", &scenario.config_path)
        .output()
        .expect("Failed to run fake claude");

    assert!(output.status.success());

    let stdout = String::from_utf8_lossy(&output.stdout);
    // Should contain first and last events
    assert!(stdout.contains("Event 0"));
    assert!(stdout.contains("Event 99"));
}
```
  </action>
  <verify>
- `cargo test e2e::test_edge_cases --` passes
- All edge case tests pass
  </verify>
  <done>Edge case E2E tests verify crash, delay, malformed output handling</done>
</task>

</tasks>

<verification>
All verification:
- `cargo test e2e::` passes (all E2E tests)
- `cargo test fake_claude::` passes (all fake claude tests)
- All infrastructure integrates correctly
- Edge cases are properly handled
</verification>

<success_criteria>
- Fake Claude binary outputs correct stream-json format
- Multi-invocation counter increments correctly
- Crash simulation works (early exit)
- Delay simulation works (measurable slowdown)
- Malformed output passthrough works
- WorkspaceBuilder + ScenarioBuilder integrate correctly in tests
</success_criteria>

<output>
After completion, create `.planning/phases/07-e2e-testing-framework/07-04-SUMMARY.md`
</output>
