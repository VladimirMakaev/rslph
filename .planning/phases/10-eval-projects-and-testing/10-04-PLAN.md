---
phase: 10-eval-projects-and-testing
plan: 04
type: execute
wave: 4
depends_on: [10-03]
files_modified:
  - evals/fizzbuzz/prompt.txt
  - evals/fizzbuzz/tests.jsonl
  - tests/eval_e2e.rs
autonomous: true

must_haves:
  truths:
    - "FizzBuzz eval project is available via --list"
    - "E2E test verifies eval command with --list flag"
    - "E2E test verifies eval command fails gracefully for unknown project"
  artifacts:
    - path: "evals/fizzbuzz/prompt.txt"
      provides: "FizzBuzz prompt for agent"
      min_lines: 10
    - path: "evals/fizzbuzz/tests.jsonl"
      provides: "Hidden test cases for FizzBuzz"
      min_lines: 15
    - path: "tests/eval_e2e.rs"
      provides: "E2E tests for eval command"
      min_lines: 30
  key_links:
    - from: "tests/eval_e2e.rs"
      to: "src/main.rs"
      via: "assert_cmd Command invocation"
      pattern: "Command::cargo_bin"
---

<objective>
Add second eval project (FizzBuzz) and E2E tests for eval command

Purpose: Provide variety in eval projects and verify eval command behavior via E2E tests
Output: FizzBuzz project with hidden tests, E2E tests covering eval --list and error cases
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-eval-projects-and-testing/10-RESEARCH.md

@evals/calculator/prompt.txt
@evals/calculator/tests.jsonl
@src/eval/projects.rs
@src/cli.rs
@tests/cli_e2e.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create FizzBuzz eval project</name>
  <files>
    - evals/fizzbuzz/prompt.txt
    - evals/fizzbuzz/tests.jsonl
  </files>
  <action>
1. Create evals/fizzbuzz/prompt.txt:
```
Build a FizzBuzz command-line program.

The program should:
1. Read a number N from stdin
2. For each number from 1 to N (inclusive):
   - Print "Fizz" if divisible by 3
   - Print "Buzz" if divisible by 5
   - Print "FizzBuzz" if divisible by both 3 and 5
   - Otherwise print the number itself
3. Print each result on a separate line

Example:
Input: "15"
Output:
1
2
Fizz
4
Buzz
Fizz
7
8
Fizz
Buzz
11
Fizz
13
14
FizzBuzz

The program should handle positive integers. You may use any programming language.
```

2. Create evals/fizzbuzz/tests.jsonl with test cases:
```json
{"input": "1", "expected": "1"}
{"input": "2", "expected": "1\n2"}
{"input": "3", "expected": "1\n2\nFizz"}
{"input": "5", "expected": "1\n2\nFizz\n4\nBuzz"}
{"input": "6", "expected": "1\n2\nFizz\n4\nBuzz\nFizz"}
{"input": "10", "expected": "1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz"}
{"input": "15", "expected": "1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz\n11\nFizz\n13\n14\nFizzBuzz"}
{"input": "20", "expected": "1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz\n11\nFizz\n13\n14\nFizzBuzz\n16\n17\nFizz\n19\nBuzz"}
```

3. Verify FizzBuzz project is embedded:
   - Add unit test to projects.rs verifying list_projects returns both "calculator" and "fizzbuzz"
  </action>
  <verify>
    cargo test projects -- --nocapture
    cargo run -- eval --list
  </verify>
  <done>
    - evals/fizzbuzz/prompt.txt exists with FizzBuzz instructions
    - evals/fizzbuzz/tests.jsonl exists with 8+ test cases
    - `rslph eval --list` shows both "calculator" and "fizzbuzz"
  </done>
</task>

<task type="auto">
  <name>Task 2: Create E2E tests for eval command</name>
  <files>
    - tests/eval_e2e.rs
  </files>
  <action>
1. Create tests/eval_e2e.rs with E2E tests using assert_cmd:

```rust
//! E2E tests for the eval command.

use assert_cmd::Command;
use predicates::prelude::*;

#[test]
fn test_eval_list_shows_projects() {
    let mut cmd = Command::cargo_bin("rslph").unwrap();
    cmd.args(["eval", "--list"])
        .assert()
        .success()
        .stdout(predicate::str::contains("calculator"))
        .stdout(predicate::str::contains("fizzbuzz"));
}

#[test]
fn test_eval_unknown_project_fails() {
    let mut cmd = Command::cargo_bin("rslph").unwrap();
    cmd.args(["eval", "nonexistent-project-xyz"])
        .assert()
        .failure()
        .stderr(predicate::str::contains("neither a built-in project nor a valid path"));
}

#[test]
fn test_eval_requires_project_or_list() {
    let mut cmd = Command::cargo_bin("rslph").unwrap();
    cmd.arg("eval")
        .assert()
        .failure()
        .stderr(predicate::str::contains("required"));
}

#[test]
fn test_eval_list_outputs_formatted() {
    let mut cmd = Command::cargo_bin("rslph").unwrap();
    cmd.args(["eval", "--list"])
        .assert()
        .success()
        .stdout(predicate::str::contains("Available built-in projects:"))
        .stdout(predicate::str::contains("  - calculator"))
        .stdout(predicate::str::contains("  - fizzbuzz"));
}

#[test]
fn test_eval_help() {
    let mut cmd = Command::cargo_bin("rslph").unwrap();
    cmd.args(["eval", "--help"])
        .assert()
        .success()
        .stdout(predicate::str::contains("Run evaluation in isolated environment"))
        .stdout(predicate::str::contains("--list"))
        .stdout(predicate::str::contains("--keep"));
}
```

Note: Full E2E test of eval execution (with plan+build) is not included because it requires Claude CLI. The tests focus on CLI argument parsing and project listing which can run without external dependencies.
  </action>
  <verify>
    cargo test eval_e2e -- --nocapture
  </verify>
  <done>
    - E2E tests for --list flag passing
    - E2E tests for error handling (unknown project)
    - E2E tests for CLI argument requirements
    - All tests pass
  </done>
</task>

</tasks>

<verification>
- `cargo build` succeeds
- `cargo test` passes all tests including new eval_e2e
- `cargo run -- eval --list` shows calculator and fizzbuzz
- FizzBuzz test data is hidden from agent (verified via get_test_data in unit tests)
</verification>

<success_criteria>
- PROJ-04: Second eval project (FizzBuzz) complete
- E2E tests verify CLI behavior without requiring Claude CLI
- Two built-in projects available for benchmarking
- Phase 10 requirements (PROJ-01 through PROJ-04, EVAL-02, EVAL-03) complete
</success_criteria>

<output>
After completion, create `.planning/phases/10-eval-projects-and-testing/10-04-SUMMARY.md`
</output>
