---
phase: 12-multi-trial-results
plan: 02
type: execute
wave: 2
depends_on: ["12-01"]
files_modified:
  - src/eval/command.rs
  - src/eval/mod.rs
  - src/main.rs
autonomous: true

must_haves:
  truths:
    - "User can run multiple independent trials with --trials N"
    - "Each trial runs in a unique workspace with trial number suffix"
    - "Statistical summary displays after all trials complete"
    - "Pass rate mean/variance/min/max shown in summary"
  artifacts:
    - path: "src/eval/command.rs"
      provides: "Multi-trial loop and aggregation logic"
      exports: ["run_eval_command"]
      contains: "for trial_num in 1..=trials"
    - path: "src/eval/mod.rs"
      provides: "MultiTrialResult struct"
      exports: ["MultiTrialResult"]
    - path: "src/main.rs"
      provides: "Trial count handling in eval command"
      contains: "trials"
  key_links:
    - from: "src/main.rs"
      to: "run_eval_command"
      via: "trials parameter"
      pattern: "run_eval_command.*trials"
    - from: "src/eval/command.rs"
      to: "TrialStatistics"
      via: "compute_statistics function"
      pattern: "compute_statistics|TrialStatistics"
---

<objective>
Modify run_eval_command to execute multiple trials and aggregate results with statistics

Purpose: Enable running N independent trials and computing statistical summary (EVAL-06, EVAL-07)
Output: Multi-trial execution loop, workspace naming with trial suffix, statistical aggregation and display
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-multi-trial-results/12-RESEARCH.md

# Prior plan artifacts
@.planning/phases/12-multi-trial-results/12-01-SUMMARY.md

# Current implementation
@src/eval/command.rs
@src/eval/mod.rs
@src/main.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add MultiTrialResult struct and refactor for single trial execution</name>
  <files>src/eval/mod.rs, src/eval/command.rs</files>
  <action>
1. Add `MultiTrialResult` struct to `src/eval/mod.rs`:
   ```rust
   #[derive(Debug, Clone)]
   pub struct MultiTrialResult {
       pub project: String,
       pub trial_count: u32,
       pub trials: Vec<EvalResult>,
       pub statistics: TrialStatistics,
   }
   ```
   Export it from the module.

2. In `src/eval/command.rs`, extract the core eval logic into a helper function:
   - Create `run_single_trial()` that takes project, trial_num, no_tui, config, cancel_token
   - This function contains the current logic from run_eval_command (steps 1-11)
   - Modify workspace naming to include trial number: `{project}-{timestamp}-trial{N}`
   - Return `EvalResult`

3. Update `run_eval_command` signature to accept `trials: u32` parameter

4. Keep the single-trial case (trials=1) working exactly as before to maintain backward compatibility
  </action>
  <verify>`cargo check` passes, existing eval tests still pass</verify>
  <done>run_single_trial extracted, MultiTrialResult struct exists, run_eval_command accepts trials param</done>
</task>

<task type="auto">
  <name>Task 2: Implement multi-trial loop with statistics aggregation</name>
  <files>src/eval/command.rs, src/main.rs</files>
  <action>
1. In `run_eval_command`, implement the trial loop:
   ```rust
   let mut trial_results = Vec::with_capacity(trials as usize);

   for trial_num in 1..=trials {
       if trials > 1 {
           println!("\n=== TRIAL {}/{} ===\n", trial_num, trials);
       }
       let result = run_single_trial(&project, trial_num, no_tui, config, cancel_token.clone()).await?;
       trial_results.push(result);
   }
   ```

2. Create `compute_statistics(trials: &[EvalResult]) -> TrialStatistics`:
   - Extract pass_rate values: `trials.iter().filter_map(|t| t.test_results.as_ref()).map(|tr| tr.pass_rate()).collect()`
   - Extract elapsed_secs, input_tokens, output_tokens, iterations
   - Use `StatSummary::from_values()` for each metric

3. Add `print_statistics(stats: &TrialStatistics, trial_count: u32)` function:
   - Print header: `=== STATISTICAL SUMMARY ({N} trials) ===`
   - Print Pass Rate: Mean, Std Dev, Min, Max
   - Print Execution Time: Mean, Std Dev, Min, Max (in seconds)
   - Print Token Usage: Mean input/output tokens

4. For trials > 1, call print_statistics after loop. For trials = 1, skip statistics display.

5. Update `src/main.rs` to pass `trials` from CLI to `run_eval_command`

6. Return `MultiTrialResult` when trials > 1, or wrap single `EvalResult` in `MultiTrialResult` for consistency
  </action>
  <verify>`cargo build` succeeds, `cargo run -- eval calculator --trials 1` works</verify>
  <done>Multi-trial loop executes, statistics computed and displayed for trials > 1</done>
</task>

<task type="auto">
  <name>Task 3: Update main.rs output handling for multi-trial results</name>
  <files>src/main.rs</files>
  <action>
1. Update the Eval command match arm to handle trials:
   - Extract trials from CLI args
   - Pass trials to run_eval_command
   - Handle output differently based on trial count

2. For trials = 1: Display same output as before (backward compatible)

3. For trials > 1:
   - Show summary of all trials (project, total time, total tokens)
   - Statistics already printed by run_eval_command
   - List workspace paths if --keep was used

4. Update the display to show trial count: `Trials: {N}`

5. Ensure all unit tests in cli.rs still pass (update test expectations if needed)
  </action>
  <verify>`cargo test --lib` passes, `cargo run -- eval --help` shows --trials flag</verify>
  <done>main.rs correctly displays multi-trial summary, single-trial backward compatible</done>
</task>

</tasks>

<verification>
- [ ] `cargo test --lib` - all tests pass
- [ ] `cargo run -- eval --help` - shows --trials flag with description
- [ ] `cargo run -- eval calculator --trials 1` - runs single trial (backward compatible)
- [ ] `cargo build --release` - no warnings
</verification>

<success_criteria>
1. `rslph eval calculator --trials 3` executes 3 independent trials
2. Each trial has unique workspace: `calculator-{timestamp}-trial1`, `calculator-{timestamp}-trial2`, etc.
3. After trials complete, statistical summary shows mean/stddev/min/max for pass rate
4. Single trial (--trials 1 or no flag) works exactly as before
</success_criteria>

<output>
After completion, create `.planning/phases/12-multi-trial-results/12-02-SUMMARY.md`
</output>
