---
phase: 13-parallel-eval-tui
plan: 03
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - src/tui/conversation.rs
  - src/tui/mod.rs
  - src/tui/app.rs
  - src/tui/ui.rs
  - src/subprocess/stream_json.rs
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User sees full LLM conversation in TUI (thinking, tool calls, text)"
    - "Thinking blocks displayed in gray italic"
    - "Tool calls displayed with colored name and summary"
    - "Conversation is scrollable with keyboard navigation"
  artifacts:
    - path: "src/tui/conversation.rs"
      provides: "Conversation display widget"
      exports: ["ConversationItem", "ConversationView", "render_conversation"]
    - path: "src/subprocess/stream_json.rs"
      provides: "Enhanced content block extraction"
      contains: "extract_conversation_items"
  key_links:
    - from: "src/subprocess/stream_json.rs"
      to: "src/tui/conversation.rs"
      via: "ContentBlock -> ConversationItem conversion"
      pattern: "extract_conversation_items"
    - from: "src/tui/ui.rs"
      to: "src/tui/conversation.rs"
      via: "render_conversation called in build TUI"
      pattern: "render_conversation"
---

<objective>
Create enhanced TUI showing full LLM conversation output with thinking blocks, tool calls, and text.

Purpose: Give users visibility into Claude's reasoning process during builds, matching the Claude Code UI experience.

Output: Scrollable conversation view in build TUI showing thinking (gray italic), tool calls (yellow), tool results (cyan), and text output.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-parallel-eval-tui/13-RESEARCH.md

@src/tui/app.rs
@src/tui/ui.rs
@src/subprocess/stream_json.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ConversationItem types and extraction from stream-json</name>
  <files>src/tui/conversation.rs, src/subprocess/stream_json.rs, src/tui/mod.rs</files>
  <action>
Create conversation display types and extraction logic:

1. Create src/tui/conversation.rs with ConversationItem enum:
   ```rust
   use crate::subprocess::stream_json::{StreamEvent, MessageContent, ContentBlock, format_tool_summary};

   /// A displayable item from the LLM conversation
   #[derive(Debug, Clone)]
   pub enum ConversationItem {
       /// Thinking block content (Claude's internal reasoning)
       Thinking(String),
       /// Text output from the assistant
       Text(String),
       /// Tool invocation with name and formatted summary
       ToolUse { name: String, summary: String },
       /// Tool result (truncated for display)
       ToolResult { name: String, output: String },
       /// System message or other event
       System(String),
   }

   /// Conversation buffer with ring-buffer behavior for memory efficiency
   #[derive(Debug, Clone, Default)]
   pub struct ConversationBuffer {
       items: Vec<ConversationItem>,
       max_items: usize,
   }

   impl ConversationBuffer {
       pub fn new(max_items: usize) -> Self {
           Self {
               items: Vec::with_capacity(max_items),
               max_items,
           }
       }

       pub fn push(&mut self, item: ConversationItem) {
           if self.items.len() >= self.max_items {
               self.items.remove(0); // Ring buffer
           }
           self.items.push(item);
       }

       pub fn items(&self) -> &[ConversationItem] {
           &self.items
       }

       pub fn len(&self) -> usize {
           self.items.len()
       }
   }
   ```

2. Add extraction function in src/subprocess/stream_json.rs:
   ```rust
   use crate::tui::conversation::ConversationItem;

   impl StreamEvent {
       /// Extract conversation items from this event for TUI display.
       pub fn extract_conversation_items(&self) -> Vec<ConversationItem> {
           let message = match &self.message {
               Some(m) => m,
               None => return vec![],
           };

           let blocks = match &message.content {
               MessageContent::Text(s) => {
                   // User message as system-type display
                   return vec![ConversationItem::System(format!("[User] {}", truncate(s, 200)))];
               }
               MessageContent::Blocks(blocks) => blocks,
               MessageContent::Empty => return vec![],
           };

           blocks.iter().filter_map(|block| {
               match block.block_type.as_str() {
                   "thinking" => {
                       block.thinking.clone().map(|t| ConversationItem::Thinking(truncate(&t, 500)))
                   }
                   "text" => {
                       block.text.clone().map(ConversationItem::Text)
                   }
                   "tool_use" => {
                       let name = block.name.clone().unwrap_or_else(|| "unknown".to_string());
                       let input_json = block.input.as_ref()
                           .map(|v| serde_json::to_string(v).unwrap_or_default())
                           .unwrap_or_default();
                       let summary = format_tool_summary(&name, &input_json);
                       Some(ConversationItem::ToolUse { name, summary })
                   }
                   "tool_result" => {
                       // Tool results come in different events - typically we'd get
                       // these from the result event, not here. Skip for now.
                       None
                   }
                   _ => None,
               }
           }).collect()
       }
   }

   fn truncate(s: &str, max_len: usize) -> String {
       if s.len() > max_len {
           format!("{}...", &s[..max_len.saturating_sub(3)])
       } else {
           s.to_string()
       }
   }
   ```

3. Export from src/tui/mod.rs:
   ```rust
   pub mod conversation;
   pub use conversation::{ConversationItem, ConversationBuffer};
   ```
  </action>
  <verify>
`cargo build` succeeds.
`cargo test` passes including stream_json tests.
  </verify>
  <done>
ConversationItem enum represents thinking, text, tool_use, tool_result, system.
extract_conversation_items parses ContentBlocks into ConversationItems.
ConversationBuffer provides ring-buffer for memory efficiency.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement conversation rendering with styled content blocks</name>
  <files>src/tui/conversation.rs</files>
  <action>
Add rendering functions to src/tui/conversation.rs:

1. Create render function for conversation items:
   ```rust
   use ratatui::{
       layout::{Constraint, Layout, Rect},
       style::{Color, Modifier, Style},
       text::{Line, Span},
       widgets::{Block, Borders, Paragraph, Wrap},
       Frame,
   };

   /// Render a conversation view with scrolling support
   pub fn render_conversation(
       frame: &mut Frame,
       area: Rect,
       items: &[ConversationItem],
       scroll_offset: usize,
   ) {
       let block = Block::default()
           .borders(Borders::ALL)
           .title("Conversation");

       let inner = block.inner(area);
       frame.render_widget(block, area);

       // Convert items to styled lines
       let mut lines: Vec<Line> = Vec::new();
       for item in items.iter().skip(scroll_offset) {
           lines.extend(render_item(item));
           lines.push(Line::from("")); // Separator
       }

       // Limit to visible area
       let visible_height = inner.height as usize;
       let visible_lines: Vec<Line> = lines.into_iter().take(visible_height).collect();

       let paragraph = Paragraph::new(visible_lines).wrap(Wrap { trim: false });
       frame.render_widget(paragraph, inner);
   }

   fn render_item(item: &ConversationItem) -> Vec<Line<'static>> {
       match item {
           ConversationItem::Thinking(text) => {
               // Gray italic for thinking
               let style = Style::default()
                   .fg(Color::DarkGray)
                   .add_modifier(Modifier::ITALIC);
               let prefix = Span::styled("[thinking] ", style.add_modifier(Modifier::BOLD));

               // Split into lines, each with thinking style
               text.lines()
                   .enumerate()
                   .map(|(i, line)| {
                       if i == 0 {
                           Line::from(vec![prefix.clone(), Span::styled(line.to_string(), style)])
                       } else {
                           Line::from(Span::styled(format!("  {}", line), style))
                       }
                   })
                   .collect()
           }
           ConversationItem::Text(text) => {
               // Normal white text
               text.lines()
                   .map(|l| Line::from(l.to_string()))
                   .collect()
           }
           ConversationItem::ToolUse { name, summary } => {
               // Yellow for tool use
               let style = Style::default().fg(Color::Yellow);
               vec![Line::from(vec![
                   Span::styled(format!("[{}] ", name), style.add_modifier(Modifier::BOLD)),
                   Span::styled(summary.clone(), style),
               ])]
           }
           ConversationItem::ToolResult { name, output } => {
               // Cyan for tool result
               let style = Style::default().fg(Color::Cyan);
               let mut lines = vec![
                   Line::from(Span::styled(format!("[{} result]", name), style.add_modifier(Modifier::BOLD)))
               ];
               for line in output.lines().take(5) { // Limit result display
                   lines.push(Line::from(Span::styled(format!("  {}", line), style)));
               }
               lines
           }
           ConversationItem::System(text) => {
               // Magenta for system messages
               let style = Style::default().fg(Color::Magenta);
               vec![Line::from(Span::styled(text.clone(), style))]
           }
       }
   }
   ```

2. Add scroll calculation helper:
   ```rust
   /// Calculate scroll offset to keep recent items visible
   pub fn calculate_scroll(item_count: usize, visible_lines: usize) -> usize {
       item_count.saturating_sub(visible_lines / 2) // Approximate lines per item
   }
   ```
  </action>
  <verify>
`cargo build` succeeds.
  </verify>
  <done>
render_conversation renders styled conversation view.
Thinking blocks in gray italic, tool calls in yellow, results in cyan.
Scroll offset support for navigating long conversations.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate conversation view into build TUI</name>
  <files>src/tui/app.rs, src/tui/ui.rs, src/tui/event.rs</files>
  <action>
Wire conversation display into the existing build TUI:

1. Add ConversationBuffer to App state in src/tui/app.rs:
   ```rust
   use crate::tui::conversation::{ConversationBuffer, ConversationItem};

   pub struct App {
       // ... existing fields ...

       /// Full conversation history for enhanced display
       pub conversation: ConversationBuffer,
       /// Scroll offset for conversation view
       pub conversation_scroll: usize,
       /// Whether to show enhanced conversation view
       pub show_conversation: bool,
   }

   impl App {
       pub fn new(/*...*/) -> Self {
           Self {
               // ... existing ...
               conversation: ConversationBuffer::new(1000), // 1000 item limit
               conversation_scroll: 0,
               show_conversation: false, // Toggle with 'c' key
           }
       }
   }
   ```

2. Update App::update() to populate conversation from stream events:
   ```rust
   impl App {
       pub fn update(&mut self, event: AppEvent) {
           match event {
               AppEvent::ClaudeOutput(stream_event) => {
                   // Existing message handling...

                   // Also extract conversation items for enhanced view
                   let items = stream_event.extract_conversation_items();
                   for item in items {
                       self.conversation.push(item);
                   }

                   // Auto-scroll to bottom
                   self.conversation_scroll = self.conversation.len().saturating_sub(20);
               }
               // ... other events ...
           }
       }
   }
   ```

3. Update src/tui/ui.rs render function to show conversation when enabled:
   ```rust
   use crate::tui::conversation::render_conversation;

   pub fn render(frame: &mut Frame, app: &App, recent_count: usize) {
       let area = frame.area();

       if app.show_conversation {
           // Split: left side for conversation, right for existing view
           let [conv_area, main_area] = Layout::horizontal([
               Constraint::Percentage(50),
               Constraint::Percentage(50),
           ]).areas(area);

           render_conversation(
               frame,
               conv_area,
               app.conversation.items(),
               app.conversation_scroll,
           );

           // Render existing TUI in right half
           render_main_view(frame, main_area, app, recent_count);
       } else {
           render_main_view(frame, area, app, recent_count);
       }
   }

   fn render_main_view(frame: &mut Frame, area: Rect, app: &App, recent_count: usize) {
       // ... existing render logic ...
   }
   ```

4. Add keyboard handler for conversation toggle and scroll in src/tui/keybindings.rs:
   ```rust
   KeyCode::Char('c') => {
       app.show_conversation = !app.show_conversation;
       false // Don't quit
   }
   KeyCode::PageUp if app.show_conversation => {
       app.conversation_scroll = app.conversation_scroll.saturating_sub(10);
       false
   }
   KeyCode::PageDown if app.show_conversation => {
       app.conversation_scroll = (app.conversation_scroll + 10)
           .min(app.conversation.len().saturating_sub(1));
       false
   }
   ```
  </action>
  <verify>
`cargo build` succeeds.
`cargo test` passes.
Running build TUI and pressing 'c' toggles conversation view.
  </verify>
  <done>
Build TUI has conversation view toggle (press 'c').
Conversation shows thinking, tool calls, text in styled format.
PageUp/PageDown scroll through conversation history.
  </done>
</task>

</tasks>

<verification>
1. `cargo build --release` succeeds without warnings
2. `cargo test` passes all tests
3. Build TUI shows conversation view when 'c' pressed
4. Thinking blocks appear gray italic, tool calls yellow, results cyan
5. Conversation scrolls with PageUp/PageDown
6. Memory stays bounded with ring buffer (1000 items max)
</verification>

<success_criteria>
1. User can view full LLM conversation in TUI (thinking blocks, tool calls, text output) in scrollable view
2. Enhanced TUI applies to `build` command with full conversation display
3. Color coding: thinking = gray italic, tool calls = yellow, results = cyan
4. 'c' toggles between standard view and split conversation view
5. PageUp/PageDown navigate conversation history
</success_criteria>

<output>
After completion, create `.planning/phases/13-parallel-eval-tui/13-03-SUMMARY.md`
</output>
