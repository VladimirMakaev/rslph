---
phase: 13-parallel-eval-tui
plan: 04
type: execute
wave: 2
depends_on: ["13-01", "13-03"]
files_modified:
  - src/planning/command.rs
  - src/tui/plan_tui.rs
  - src/tui/mod.rs
  - src/cli.rs
  - src/main.rs
autonomous: true
user_setup: []

must_haves:
  truths:
    - "User sees streaming LLM output during plan command with TUI"
    - "Plan TUI shows thinking blocks, tool calls, text output like build TUI"
    - "Generated plan preview is displayed as it streams"
  artifacts:
    - path: "src/tui/plan_tui.rs"
      provides: "TUI mode for plan command"
      exports: ["run_plan_tui", "PlanTuiState"]
    - path: "src/planning/command.rs"
      provides: "Integration of TUI mode into plan command"
      contains: "run_plan_tui"
  key_links:
    - from: "src/main.rs"
      to: "src/planning/command.rs"
      via: "--tui flag triggers TUI mode"
      pattern: "tui.*run_plan"
    - from: "src/planning/command.rs"
      to: "src/tui/plan_tui.rs"
      via: "spawns TUI when tui flag enabled"
      pattern: "run_plan_tui"
---

<objective>
Add TUI mode to plan command with streaming LLM output display.

Purpose: Provide consistent TUI experience across plan and build commands, showing Claude's reasoning during planning.

Output: `rslph plan "my idea" --tui` shows streaming output with thinking blocks, tool calls, and generated plan preview.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-parallel-eval-tui/13-RESEARCH.md
@.planning/phases/13-parallel-eval-tui/13-03-SUMMARY.md

@src/planning/command.rs
@src/tui/run.rs
@src/tui/conversation.rs
@src/cli.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add --tui flag to plan command CLI</name>
  <files>src/cli.rs</files>
  <action>
Add TUI flag to the Plan command in src/cli.rs:

1. Add tui flag to Commands::Plan variant:
   ```rust
   /// Transform idea/plan into structured progress file (CMD-01)
   Plan {
       /// Path to the plan/idea file or inline text
       plan: String,

       /// Use adaptive mode with clarifying questions
       #[arg(long)]
       adaptive: bool,

       /// Enable TUI mode with streaming output
       #[arg(long)]
       tui: bool,
   },
   ```

2. Add unit test for parsing --tui flag:
   ```rust
   #[test]
   fn test_parse_plan_with_tui() {
       let cli = Cli::try_parse_from([
           "rslph", "plan", "my-idea.txt", "--tui"
       ]).expect("Should parse");
       match cli.command {
           Commands::Plan { plan, adaptive, tui } => {
               assert_eq!(plan, "my-idea.txt");
               assert!(!adaptive);
               assert!(tui);
           }
           _ => panic!("Expected Plan command"),
       }
   }
   ```
  </action>
  <verify>
`cargo test test_parse_plan_with_tui` passes.
`cargo build` succeeds.
`./target/debug/rslph plan --help` shows --tui flag.
  </verify>
  <done>
--tui flag available on plan command.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create plan TUI module with streaming display</name>
  <files>src/tui/plan_tui.rs, src/tui/mod.rs</files>
  <action>
Create src/tui/plan_tui.rs for plan command TUI:

1. Define PlanTuiState:
   ```rust
   use crate::tui::conversation::{ConversationBuffer, ConversationItem};
   use crate::subprocess::stream_json::StreamEvent;
   use std::time::Instant;

   pub struct PlanTuiState {
       /// Conversation history
       pub conversation: ConversationBuffer,
       /// Scroll offset
       pub scroll_offset: usize,
       /// Generated plan preview (extracted from text output)
       pub plan_preview: String,
       /// Current status
       pub status: PlanStatus,
       /// Start time
       pub start_time: Instant,
       /// Should quit flag
       pub should_quit: bool,
   }

   pub enum PlanStatus {
       StackDetection,
       Planning,
       GeneratingName,
       Complete,
       Failed(String),
   }

   impl PlanTuiState {
       pub fn new() -> Self {
           Self {
               conversation: ConversationBuffer::new(500),
               scroll_offset: 0,
               plan_preview: String::new(),
               status: PlanStatus::StackDetection,
               start_time: Instant::now(),
               should_quit: false,
           }
       }

       pub fn update(&mut self, event: &StreamEvent) {
           // Extract conversation items
           for item in event.extract_conversation_items() {
               // If it's text, also append to plan preview
               if let ConversationItem::Text(ref text) = item {
                   self.plan_preview.push_str(text);
                   self.plan_preview.push('\n');
               }
               self.conversation.push(item);
           }

           // Auto-scroll to bottom
           self.scroll_offset = self.conversation.len().saturating_sub(15);
       }
   }
   ```

2. Create render function:
   ```rust
   use ratatui::{
       layout::{Constraint, Direction, Layout, Rect},
       style::{Color, Modifier, Style},
       text::{Line, Span},
       widgets::{Block, Borders, Paragraph, Wrap},
       Frame,
   };
   use crate::tui::conversation::render_conversation;

   pub fn render_plan_tui(frame: &mut Frame, state: &PlanTuiState) {
       let area = frame.area();

       // Split: top for status, middle for conversation, bottom for plan preview
       let [header_area, main_area, footer_area] = Layout::vertical([
           Constraint::Length(3),
           Constraint::Min(10),
           Constraint::Length(5),
       ]).areas(area);

       // Header: status and elapsed time
       let elapsed = state.start_time.elapsed().as_secs();
       let status_text = match &state.status {
           PlanStatus::StackDetection => "Detecting project stack...",
           PlanStatus::Planning => "Generating plan...",
           PlanStatus::GeneratingName => "Generating project name...",
           PlanStatus::Complete => "Complete!",
           PlanStatus::Failed(e) => e.as_str(),
       };
       let header = Paragraph::new(vec![
           Line::from(vec![
               Span::styled("Plan ", Style::default().add_modifier(Modifier::BOLD)),
               Span::raw(format!("| {} | {}s", status_text, elapsed)),
           ]),
       ])
       .block(Block::default().borders(Borders::BOTTOM));
       frame.render_widget(header, header_area);

       // Conversation view
       render_conversation(
           frame,
           main_area,
           state.conversation.items(),
           state.scroll_offset,
       );

       // Footer: plan preview (last few lines)
       let preview_lines: Vec<Line> = state.plan_preview
           .lines()
           .rev()
           .take(3)
           .map(|l| Line::from(l.to_string()))
           .collect::<Vec<_>>()
           .into_iter()
           .rev()
           .collect();

       let footer = Paragraph::new(preview_lines)
           .block(Block::default()
               .borders(Borders::TOP)
               .title("Plan Preview"));
       frame.render_widget(footer, footer_area);
   }
   ```

3. Create TUI run loop:
   ```rust
   use tokio::sync::mpsc;
   use tokio_util::sync::CancellationToken;
   use crate::tui::terminal::{init_terminal, restore_terminal};
   use crate::tui::event::EventHandler;
   use crate::error::RslphError;
   use crossterm::event::{KeyCode, KeyEvent};

   pub async fn run_plan_tui(
       event_rx: mpsc::UnboundedReceiver<StreamEvent>,
       cancel_token: CancellationToken,
   ) -> Result<PlanTuiState, RslphError> {
       let mut terminal = init_terminal()
           .map_err(|e| RslphError::Subprocess(format!("Terminal init failed: {}", e)))?;

       let mut state = PlanTuiState::new();
       let mut event_rx = event_rx;

       // Create event handler for keyboard input
       let (mut kbd_handler, _) = EventHandler::new(30);

       loop {
           // Render
           terminal.draw(|frame| render_plan_tui(frame, &state))
               .map_err(|e| RslphError::Subprocess(format!("Render failed: {}", e)))?;

           tokio::select! {
               biased;

               _ = cancel_token.cancelled() => {
                   break;
               }

               stream_event = event_rx.recv() => {
                   match stream_event {
                       Some(event) => {
                           state.update(&event);
                       }
                       None => {
                           // Stream complete
                           state.status = PlanStatus::Complete;
                           break;
                       }
                   }
               }

               kbd_event = kbd_handler.next() => {
                   if let Some(crate::tui::event::Event::Key(KeyEvent { code, .. })) = kbd_event {
                       match code {
                           KeyCode::Char('q') | KeyCode::Esc => {
                               state.should_quit = true;
                               cancel_token.cancel();
                               break;
                           }
                           KeyCode::PageUp => {
                               state.scroll_offset = state.scroll_offset.saturating_sub(5);
                           }
                           KeyCode::PageDown => {
                               state.scroll_offset = (state.scroll_offset + 5)
                                   .min(state.conversation.len().saturating_sub(1));
                           }
                           _ => {}
                       }
                   }
               }
           }
       }

       restore_terminal()
           .map_err(|e| RslphError::Subprocess(format!("Terminal restore failed: {}", e)))?;

       Ok(state)
   }
   ```

4. Export from src/tui/mod.rs:
   ```rust
   pub mod plan_tui;
   pub use plan_tui::{run_plan_tui, PlanTuiState, PlanStatus};
   ```
  </action>
  <verify>
`cargo build` succeeds.
  </verify>
  <done>
PlanTuiState tracks conversation, plan preview, status.
render_plan_tui displays header, conversation, plan preview.
run_plan_tui provides async event loop with keyboard handling.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate TUI mode into plan command</name>
  <files>src/planning/command.rs, src/main.rs</files>
  <action>
Wire TUI mode into the plan command:

1. Update run_plan_command signature in src/planning/command.rs:
   ```rust
   pub async fn run_plan_command(
       input: &str,
       adaptive: bool,
       tui: bool,  // NEW
       config: &Config,
       working_dir: &Path,
       cancel_token: CancellationToken,
       timeout: Duration,
   ) -> color_eyre::Result<(PathBuf, TokenUsage)>
   ```

2. Add TUI branch in run_basic_planning or create run_tui_planning helper:
   ```rust
   async fn run_tui_planning(
       input: &str,
       config: &Config,
       working_dir: &Path,
       cancel_token: CancellationToken,
       timeout: Duration,
   ) -> color_eyre::Result<(PathBuf, TokenUsage)> {
       use crate::tui::plan_tui::run_plan_tui;
       use tokio::sync::mpsc;

       // Detect stack
       let stack = detect_stack(working_dir);
       let system_prompt = get_plan_prompt(config)?;
       let full_input = format!(
           "## Detected Stack\n{}\n\n## User Request\n{}",
           stack.to_summary(),
           input
       );

       // Build Claude CLI args
       let args = vec![
           "--internet".to_string(),
           "-p".to_string(),
           "--verbose".to_string(),
           "--output-format".to_string(),
           "stream-json".to_string(),
           "--system-prompt".to_string(),
           system_prompt,
           full_input,
       ];

       // Spawn Claude
       let mut runner = ClaudeRunner::spawn(&config.claude_path, &args, working_dir)
           .await
           .map_err(|e| RslphError::Subprocess(format!("Failed to spawn claude: {}", e)))?;

       // Create channel for stream events
       let (event_tx, event_rx) = mpsc::unbounded_channel();

       // Spawn TUI task
       let tui_cancel = cancel_token.clone();
       let tui_handle = tokio::spawn(async move {
           run_plan_tui(event_rx, tui_cancel).await
       });

       // Stream events to TUI
       let mut stream_response = StreamResponse::new();
       loop {
           tokio::select! {
               biased;

               _ = cancel_token.cancelled() => {
                   runner.terminate_gracefully(Duration::from_secs(5)).await?;
                   break;
               }

               line = runner.next_output() => {
                   match line {
                       Some(OutputLine::Stdout(s)) => {
                           if let Ok(event) = StreamEvent::parse(&s) {
                               stream_response.process_event(&event);
                               let _ = event_tx.send(event);
                           }
                       }
                       Some(OutputLine::Stderr(_)) => {}
                       None => break,
                   }
               }
           }
       }

       // Drop sender to signal completion
       drop(event_tx);

       // Wait for TUI to finish
       let tui_state = tui_handle.await
           .map_err(|e| RslphError::Subprocess(format!("TUI task failed: {}", e)))?
           .map_err(|e| RslphError::Subprocess(format!("TUI error: {}", e)))?;

       if tui_state.should_quit {
           return Err(RslphError::Cancelled.into());
       }

       // Parse and write progress file
       let mut progress_file = ProgressFile::parse(&stream_response.text)?;
       if progress_file.name.is_empty() {
           // Generate name (non-TUI for simplicity)
           progress_file.name = generate_project_name(...).await?;
       }

       let output_path = working_dir.join("progress.md");
       progress_file.write(&output_path)?;

       let tokens = TokenUsage {
           input_tokens: stream_response.input_tokens,
           output_tokens: stream_response.output_tokens,
           cache_creation_input_tokens: stream_response.cache_creation_input_tokens,
           cache_read_input_tokens: stream_response.cache_read_input_tokens,
       };

       Ok((output_path, tokens))
   }
   ```

3. Update run_plan_command to dispatch to TUI mode:
   ```rust
   pub async fn run_plan_command(..., tui: bool, ...) -> ... {
       if tui {
           return run_tui_planning(input, config, working_dir, cancel_token, timeout).await;
       }
       if adaptive {
           return run_adaptive_planning(...).await;
       }
       run_basic_planning(...).await
   }
   ```

4. Update src/main.rs to pass tui flag:
   ```rust
   Commands::Plan { plan, adaptive, tui } => {
       // ... existing code ...
       run_plan_command(&input, adaptive, tui, &config, &working_dir, cancel_token, timeout).await
   }
   ```
  </action>
  <verify>
`cargo build` succeeds.
`cargo test` passes.
Running `./target/debug/rslph plan "build a calculator" --tui` shows TUI with streaming output.
  </verify>
  <done>
Plan command supports --tui flag for TUI mode.
TUI shows streaming conversation with thinking, tool calls, text.
Plan preview updates as Claude generates plan.
  </done>
</task>

</tasks>

<verification>
1. `cargo build --release` succeeds without warnings
2. `cargo test` passes all tests including new CLI parsing tests
3. `rslph plan "my idea" --tui` shows TUI with streaming output
4. TUI displays thinking blocks, tool calls, and text like build TUI
5. Generated plan preview updates in real-time
6. 'q' or Esc quits TUI and cancels planning
7. PageUp/PageDown scroll conversation
</verification>

<success_criteria>
1. `plan` command has TUI mode showing streaming LLM output, tool calls, thinking blocks, and generated plan preview
2. TUI matches enhanced conversation display style from build command
3. Keyboard navigation works (q to quit, PageUp/PageDown to scroll)
4. Plan preview shows last few lines of generated plan as it streams
5. Status bar shows current phase (detecting stack, planning, generating name, complete)
</success_criteria>

<output>
After completion, create `.planning/phases/13-parallel-eval-tui/13-04-SUMMARY.md`
</output>
